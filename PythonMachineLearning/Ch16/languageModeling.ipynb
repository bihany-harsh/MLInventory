{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length:  1130712\n",
      "Unique characters:  85\n"
     ]
    }
   ],
   "source": [
    "# reading and processing text\n",
    "with open('dataset/1268-0.txt') as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "\n",
    "char_set = set(text)\n",
    "\n",
    "print('Total length: ', len(text))\n",
    "print('Unique characters: ', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "\n",
    "char2int = {ch: i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130712,)\n",
      "THE MYSTERIOUS  == Encoding ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
      "[37 47 40 29 42 32] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "\n",
    "print(text_encoded[15:21], '== Reverse ==>',''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 18:32:03.771258: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 18:32:04.193002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-17 18:32:04.193040: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-17 18:32:05.385731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 18:32:05.385803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 18:32:05.385809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/harsh/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 -> T\n",
      "36 -> H\n",
      "33 -> E\n",
      "1 ->  \n",
      "41 -> M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 18:33:16.544966: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-17 18:33:16.545053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: harsh-IdeaPad-Gaming3-15ARH05D\n",
      "2022-12-17 18:33:16.545067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: harsh-IdeaPad-Gaming3-15ARH05D\n",
      "2022-12-17 18:33:16.545245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.1\n",
      "2022-12-17 18:33:16.545657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  515.65.01  Release Build  (dvs-builder@U16-T11-05-2)  Wed Jul 20 13:54:56 UTC 2022\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n",
      "\"\n",
      "2022-12-17 18:33:16.549989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "# define the function for splitiing x and y\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (X) :  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "\n",
      "Input (X) :  'OUS ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPAR'\n",
      "Target (y):  'US ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPART'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print('Input (X) : ', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y): ', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a character-level **RNN Mdoel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(\n",
    "            rnn_units,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 256)         21760     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 512)         1574912   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 85)          43605     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,640,277\n",
      "Trainable params: 1,640,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# setting the trainig parameters\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "model = build_model(\n",
    "    vocab_size=charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "431/431 [==============================] - 177s 403ms/step - loss: 2.3260\n",
      "Epoch 2/20\n",
      "431/431 [==============================] - 149s 343ms/step - loss: 1.7309\n",
      "Epoch 3/20\n",
      "431/431 [==============================] - 149s 343ms/step - loss: 1.5269\n",
      "Epoch 4/20\n",
      "431/431 [==============================] - 197s 455ms/step - loss: 1.4139\n",
      "Epoch 5/20\n",
      "431/431 [==============================] - 216s 497ms/step - loss: 1.3428\n",
      "Epoch 6/20\n",
      "431/431 [==============================] - 209s 481ms/step - loss: 1.2935\n",
      "Epoch 7/20\n",
      "431/431 [==============================] - 187s 431ms/step - loss: 1.2557\n",
      "Epoch 8/20\n",
      "431/431 [==============================] - 174s 400ms/step - loss: 1.2259\n",
      "Epoch 9/20\n",
      "431/431 [==============================] - 195s 449ms/step - loss: 1.2006\n",
      "Epoch 10/20\n",
      "431/431 [==============================] - 217s 501ms/step - loss: 1.1783\n",
      "Epoch 11/20\n",
      "431/431 [==============================] - 195s 448ms/step - loss: 1.1589\n",
      "Epoch 12/20\n",
      "431/431 [==============================] - 213s 490ms/step - loss: 1.1407\n",
      "Epoch 13/20\n",
      "431/431 [==============================] - 215s 495ms/step - loss: 1.1238\n",
      "Epoch 14/20\n",
      "431/431 [==============================] - 201s 462ms/step - loss: 1.1076\n",
      "Epoch 15/20\n",
      "431/431 [==============================] - 186s 428ms/step - loss: 1.0926\n",
      "Epoch 16/20\n",
      "431/431 [==============================] - 214s 494ms/step - loss: 1.0781\n",
      "Epoch 17/20\n",
      "431/431 [==============================] - 216s 497ms/step - loss: 1.0638\n",
      "Epoch 18/20\n",
      "431/431 [==============================] - 155s 356ms/step - loss: 1.0504\n",
      "Epoch 19/20\n",
      "431/431 [==============================] - 155s 355ms/step - loss: 1.0368\n",
      "Epoch 20/20\n",
      "431/431 [==============================] - 159s 365ms/step - loss: 1.0236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5dc106eb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True\n",
    "    )\n",
    ")\n",
    "\n",
    "model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of auto regression\n",
    "\n",
    "def sample(model, starting_str, len_generated_text=500, max_input_length=40, scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "        # to remove unwanted dimensions\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "\n",
    "        new_char_indx = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()\n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "\n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        # adds a new dimension\n",
    "\n",
    "        encoded_input = tf.concat([encoded_input, new_char_indx], axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island may have been exheard. But these woods effected into the corral. Top and if\n",
      "we are going to lear out necessary to stop her to be convenient\n",
      "for the wound!\n",
      "\n",
      "In fact, Pencroft, to keeping the house, and still strenched to the cliff which would ran place some emotion, the point was secret on the islet besides after, and\n",
      "Herbert, under all they publigged but to set, to then be\n",
      "mentioned; Captain Harding,” replied Cyrus Harding. “The colonists, were falled one of the colonists; the wind, and\n",
      "this qu\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was being worked them\n",
      "in the corral. The colonists were confided to the engineer and his companions were not attacked on the shore.\n",
      "\n",
      "The colonists were not reason to prevent it.”\n",
      "\n",
      "“And what was the box was a large number, a convicts for the corral alone to the attacks of the colonists like the island.\n",
      "\n",
      "The colonists were determined to the colonists were to be feared that the stores of lava would have\n",
      "been easily as a sort of all that the others worked with the corral.\n",
      "\n",
      "Herbert and Herbert, and \n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='The island', scale_factor=2.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
